{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fea50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fedac",
   "metadata": {},
   "source": [
    "### Tensor Reshaping explained\n",
    "\n",
    "When you create a tensor with `x = torch.arange(1,11)`, you get a 1D tensor with shape `torch.Size([10])`. Visualizing this is as 10 boxes in a single row:\n",
    "\n",
    "```\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "```\n",
    "\n",
    "Now we'll shape it using `x.reshape(1,10)` where `(1,10)` is the new shape of the tensor.\n",
    "\n",
    "When you reshape it to `x.reshape(1,10)` resulting in `torch.Size([1,10])`, the tensor still contains exactly 10 elements but you're reorganizing how these elements are conceptually arranged in a different dimensional structure.\n",
    "\n",
    "The new shape represents a 2D tensor with **1 row and 10 columns**:\n",
    "\n",
    "```\n",
    "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    "```\n",
    "\n",
    "Notice the extra set of brackets - this represents the added dimension. You now have a tensor with 2 dimensions (a matrix), but the first dimension has size 1. This is often called \"adding a batch dimension\" in deep learning contexts.\n",
    "\n",
    "In PyTorch, reshaping operations like `view()` or `reshape()` never change the total number of elements in the tensor. They just reorganize how these elements are arranged within the dimensional structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0a47b",
   "metadata": {},
   "source": [
    "> NOTE: you can also reshape a tensor using the syntax `torch.reshape(tensor, (dim1,dim2,...)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9006268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,11) \n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# reshaping x\n",
    "x_reshaped = x.reshape(1,10)\n",
    "print(x_reshaped)\n",
    "print(x_reshaped.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbad7e0",
   "metadata": {},
   "source": [
    "### Changing the View of the Tensor\n",
    "\n",
    "When you create a tensor out of a initial tensor by changing the view. it'll refer to the same tensor as the initial tensor (unlike in reshaping, where the new tensor after reshaping is a independent tensor in memory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e70e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([[1, 2, 3, 4, 5]])\n",
      "tensor([100,   2,   3,   4,   5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,6)\n",
    "z = x.view(1,5)\n",
    "print(x)\n",
    "print(z)\n",
    "\n",
    "# Here, changing z will change x (because they refer to the same tensor in memory!)\n",
    "z[0,0]=100 # changing the element in 0th row and 0th col\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6522a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100,   2,   3,   4,   5],\n",
       "        [100,   2,   3,   4,   5],\n",
       "        [100,   2,   3,   4,   5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also stack vectors along a dimension\n",
    "y = torch.stack((x,x,x), dim=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a69c44",
   "metadata": {},
   "source": [
    "### Squeezing and Unsqueezing a Tensor\n",
    "\n",
    "Squeezing: All the dimensions of size 1 will be removed from the tensor. The new tensor returned will share the same memory as the input tensor. So changing the new tensor, changes the input tensor\n",
    "\n",
    "Unsqueezing: Returns a tensor with a dimension of size 1 inserted at a specified position. In this also, the returned tensor shares the same memory as the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b25149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 1])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1,2,3,1)\n",
    "print(x.size()) \n",
    "\n",
    "x_squeezed = torch.squeeze(x)\n",
    "print(x_squeezed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4,5) \n",
    "print(x.size())\n",
    "x_unsqueezed = torch.unsqueeze(x, 0) # inserted a dimension of size 1 at the 0th dimension \n",
    "print(x_unsqueezed.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3105d4",
   "metadata": {},
   "source": [
    "### Permuting a Tensor\n",
    "\n",
    "Changes the **order of dimensions** of a tensor. Again, the new tensor returned shares the same memory space as the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea8d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3,4) \n",
    "print(x.size()) \n",
    "x_permuted = torch.permute(x,(2,1,0)) \n",
    "# dimension of size 2 at 0th index (in input/original tensor) goes to 2nd index\n",
    "# dimension of size 3 at 1st index goes to 1st index\n",
    "# dimension of size 4 at 2nd index goes to 0th index\n",
    "print(x_permuted.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
